{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "l0WsYEjanMyn",
        "outputId": "a813b1cc-7cca-4715-f018-60f13b15497f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "R3IFzCrHGDtL",
        "outputId": "b825a37d-0ef9-428a-d2d8-f5eed8e9ff72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "Collecting tqdm>=4.27\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from transformers) (1.21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from transformers) (2.26.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from transformers) (21.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (3.3.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2021.11.10-cp38-cp38-win_amd64.whl (273 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\envs\\amrita_working\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from sacremoses->transformers) (1.16.0)\n",
            "Installing collected packages: tqdm, regex, pyyaml, joblib, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.1.2 joblib-1.1.0 pyyaml-6.0 regex-2021.11.10 sacremoses-0.0.46 tokenizers-0.10.3 tqdm-4.62.3 transformers-4.12.5\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ETHwJVosnYbg"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13936/2018634376.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT5Config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json \n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0WHwd69en5XJ"
      },
      "outputs": [],
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Sqmeo3Gyn8s0"
      },
      "outputs": [],
      "source": [
        "\n",
        "text =\"\"\"\n",
        "\"Ultimately what really matters is you getting two points. What T20s have shown is that there are a few games that don't go your way and then there are some that go your way even when you haven't earned it. Today I felt we did a very good job even in batting. There was some purpose with the bat and the batsmen assessed the situation very well. With a total like 160, it all depends on the start you get in the first six overs. The fast bowlers did the job, the spinners came into play and it was one game that was as close to being perfect. It was a par score and I usually assess scores after the first six overs. If there are misfields in the first six overs then a par score becomes an under par score. A lot depended on the fast bowlers. I just told them to be expressive on the field and hit their areas. There are some two paced balls, some swing and some don't swing, some get extra bounce. What was needed was good execution of the plans and that was done by the fast bowlers. To an extent yes (these pitches). But we used an extra spinner because an Indian batter hasn't done well for us. That's why Sam Curran went up and it wasn't fair on Jagadeesan as well to bat at seven or eight. Sam Curran is a complete cricketer for us. You need a seamin all-rounder, he plays the spinners well and he can give us those 15-45 runs.\"\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Uzj3g5SwpUP7",
        "outputId": "729780a7-e5ba-42b8-c44b-66d1e8622e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original text preprocessed: \n",
            " \"Ultimately what really matters is you getting two points. What T20s have shown is that there are a few games that don't go your way and then there are some that go your way even when you haven't earned it. Today I felt we did a very good job even in batting. There was some purpose with the bat and the batsmen assessed the situation very well. With a total like 160, it all depends on the start you get in the first six overs. The fast bowlers did the job, the spinners came into play and it was one game that was as close to being perfect. It was a par score and I usually assess scores after the first six overs. If there are misfields in the first six overs then a par score becomes an under par score. A lot depended on the fast bowlers. I just told them to be expressive on the field and hit their areas. There are some two paced balls, some swing and some don't swing, some get extra bounce. What was needed was good execution of the plans and that was done by the fast bowlers. To an extent yes (these pitches). But we used an extra spinner because an Indian batter hasn't done well for us. That's why Sam Curran went up and it wasn't fair on Jagadeesan as well to bat at seven or eight. Sam Curran is a complete cricketer for us. You need a seamin all-rounder, he plays the spinners well and he can give us those 15-45 runs.\"\n"
          ]
        }
      ],
      "source": [
        "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
        "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
        "#print (\"original text preprocessed: \\n\", preprocess_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VyY7ZdhRpWK6"
      },
      "outputs": [],
      "source": [
        "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GR1fM3eppYgc"
      },
      "outputs": [],
      "source": [
        "summary_ids = model.generate(tokenized_text,\n",
        "                                    num_beams=4,\n",
        "                                    no_repeat_ngram_size=2,\n",
        "                                    min_length=30,\n",
        "                                    max_length=200,\n",
        "                                    early_stopping=True)\n",
        "\n",
        "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNfivhPttiYZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "1lfdprH_paRS",
        "outputId": "dd11e167-c0fd-45bd-928d-2692e7ccb669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Summarized text: \n",
            " the fast bowlers did the job, the spinners came into play and it was one game that was as close to being perfect. if there are misfields in the first six overs then a par score becomes an under Par score.\n"
          ]
        }
      ],
      "source": [
        "print (\"\\n\\nSummarized text: \\n\",output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrHWJ-fnpruy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Summarizer - T5",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
